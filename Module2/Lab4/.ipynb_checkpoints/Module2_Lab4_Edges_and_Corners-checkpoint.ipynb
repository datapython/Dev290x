{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2, Lab 4, \"Edges and Corners\"\n",
    "\n",
    "# Recap\n",
    "\n",
    "This is the fourth and final lab for Lesson 2 - Classical Image Segmention in Dev290x. You should complete the tasks in this lab as part of the Edges section of the lesson.\n",
    "\n",
    "Please remember this lab must be completed before taking the quiz at the end of this lesson.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this lab you will complete your fouth image segmentation project where you will use the Canny algorithm to identify the edges in a martini glass. You will them use dilation, erosing, and contour handling to segment the martini glass from the background of the image.\n",
    "\n",
    "You will also identify the corners of the image.\n",
    "\n",
    "At the end of the lab we'll review the work we've done and assess what types of images and projects these approaches are effective for.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "In this lab, you will: \n",
    "* learn about one introductary 'edge detection' image segmentation techique - 'Canny';\n",
    "* again see how deblurring, thresholding, dilation, opening, are needed *particularly* with edge detection where closing contours is a common issue;\n",
    "* use those techniques to segment an image with straight edges - the martini glass;\n",
    "* use the Harris algorithm to detect corners in the martini glass image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Image segmentation is the process of partitioning a digital image into multiple segments to make the image easier to analyze.  Often we are looking to locate objects and boundaries in the original image.  Another way of looking at it is image segmentation's goal is to assign a label to every pixel in an image such that pixels with the same label share certain characteristics.  Like many elements of computer vision, I find an example is often more useful than precise text.\n",
    "\n",
    "For example, these images show a typical road scene on the left and a segmented version of the image on the right.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"../Images/bg-road.png\" width=\"450\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Detection\n",
    "\n",
    "In this technique, we will see how to use the Canny algorithm along with some dilation and erosion to segment our martini glass image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, first you must load the libraries that you''ll need for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All you need for this lab is OpenCV, numpy and pyplot\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load the martini glass and experiment with the edges provided by the Canny algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the martini image as grayscale.\n",
    "img = cv2.imread(\"../Images/martini.png\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Run Canny's edge detection over the martini\n",
    "# glass with TODO as parameters.\n",
    "edges = cv2.Canny(gray, 100, 200)\n",
    "plt.grid(False)\n",
    "plt.axis('off')\n",
    "plt.imshow(edges, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be seeing an image similar to this one.\n",
    "\n",
    "<img src=\"../Images/martini_canny.png\" alt=\"Martini glass\" align=\"left\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the issues with edge based detections is that they tend to be non-contiguous.  So, we have some work to do to join the dots (literally).\n",
    "\n",
    "There's a variety of approaches you can use. I'd like you to solve this one on your own!\n",
    "\n",
    "If you want to follow a trodden path instead of exploring on your own, I do have\n",
    "a hint for you.  There's a simple operation that we've used several times in these\n",
    "labs already to go from an image like the one above to an image like the one below.\n",
    "\n",
    "<img src=\"../Images/martini_canny_dilated6.png\" alt=\"Martini glass Dilated\" align=\"left\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# You should have everything you need if you consult the other labs.\n",
    "\n",
    "# HINT: I dilated the image 6 times with the kernel below and then used findContours and drawContours as the basis of the mask\n",
    "# The key is getting a good contour line.  Lots of techniques will work here!\n",
    "\n",
    "# Hint: You'll find answers at the bottom of this lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that it should just be a case of extracting the largest contour in the scene and creating a mask based on that.  If you can''t recall how, there is code to do just that in one of the earlier labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the contours - just external contours to keep post-processing simple\n",
    "_, contours, _ = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Sort the candidates by size, keep the largest one\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)[:1]\n",
    "\n",
    "# Create two related images - one contains the shape of the martini\n",
    "# glass with black (0's) in the remainder, the other contains\n",
    "# black where the martini glass is and a colour everywhere else\n",
    "h, w, num_c = img.shape\n",
    "segmask = np.zeros((h, w, num_c), np.uint8)\n",
    "stencil = np.zeros((h, w, num_c), np.uint8)\n",
    "\n",
    "for c in contours:\n",
    "    cv2.drawContours(segmask, [c], 0, (255, 0, 0), -1)\n",
    "    cv2.drawContours(stencil, [c], 0, (255, 0, 0), -1)\n",
    "\n",
    "# Rearrange the colors in the stencil.  Anything that's black\n",
    "# replace with green.\n",
    "stencil[np.where((stencil==[0,0,0]).all(axis=2))] = [0, 255, 0]\n",
    "# Now its safe to convert the blue to black\n",
    "stencil[np.where((stencil==[255,0,0]).all(axis=2))] = [0, 0, 0]\n",
    "\n",
    "# Add the two images (or or them if you prefer)\n",
    "mask = cv2.bitwise_or(stencil, segmask)\n",
    "plt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "output = cv2.bitwise_or(mask, img)\n",
    "# plt.imshow(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal is to produce an image similar to this reference image.\n",
    "\n",
    "<img src=\"../Images/martini_canny_segmented.png\" alt=\"Martini glass Segmented\" align=\"left\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corners\n",
    "\n",
    "Our last mini-lab is just to introduce you to another key feature that is used in image segmentation - corners.  We'll have a look at the Harris corner detection algorithm now.\n",
    "\n",
    "Please complete this lab in conjunction with the 'Edges and Corners' lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've already loaded the necessary libraries, so nothing to do here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You already have a grayscale image - convert it to float32's\n",
    "gray = np.float32(gray)\n",
    "\n",
    "corners = cv2.cornerHarris(gray, 2, 3, 0.04)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, put your corners onto the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Adjust this threshold until you see an image similar to the reference image below\n",
    "\n",
    "\n",
    "# Threshold may vary\n",
    "img[corners>threshold * corners.max()]=[255, 0, 0]\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your target is to generate an image similar to this reference image.\n",
    "\n",
    "<img src=\"../Images/martini_harris.png\" alt=\"Martini Harris\" align=\"left\" style=\"width: 300px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "So, that completes the fourth and final lab in this lesson.\n",
    "\n",
    "You''ve learned about edges and corners\n",
    "You''ve learned how to use the Canny algorithm to segment an image that has edges.\n",
    "You''ve learned about Harris corner detection and used it to detect corners in the martini glass image.\n",
    "\n",
    "You've gained an insight that classical techniques involve manually tuning features like super-pixel size and trying to gauge the relative importance of colour, edges, corners, textures, etc for a particlar image or set of images.\n",
    "\n",
    "You should now be ready for the neural network part of this course where you'll let the neural network manage these types of trade-offs itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution for Edge Detection Missing Code**:\n",
    "\n",
    "    kernel = np.ones((10,10),np.uint8)\n",
    "    dilation = cv2.dilate(edges,kernel,iterations = 6)\n",
    "\n",
    "    plt.imshow(dilation, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Solution for the Threshold Missing Code:**\n",
    "    \n",
    "    threshold = 0.001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
